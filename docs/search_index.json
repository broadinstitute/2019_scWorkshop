[
["index.html", "ANALYSIS OF SINGLE CELL RNA-SEQ DATA 1 Introduction 1.1 COURSE OVERVIEW 1.2 TARGETED AUDIENCE &amp; ASSUMED BACKGROUND 1.3 COURSE FORMAT 1.4 Getting Started 1.5 SESSION CONTENT", " ANALYSIS OF SINGLE CELL RNA-SEQ DATA Orr Ashenberg Dana Silverbush Kirk Gosik 2019-02-25 1 Introduction 1.1 COURSE OVERVIEW In recent years single cell RNA-seq (scRNA-seq) has become widely used for transcriptome analysis in many areas of biology. In contrast to bulk RNA-seq, scRNA-seq provides quantitative measurements of the expression of every gene in a single cell. However, to analyze scRNA-seq data, novel methods are required and some of the underlying assumptions for the methods developed for bulk RNA-seq experiments are no longer valid. In this course we will cover all steps of the scRNA-seq processing, starting from the raw reads coming off the sequencer. The course includes common analysis strategies, using state-of-the-art methods and we also discuss the central biological questions that can be addressed using scRNA-seq. 1.2 TARGETED AUDIENCE &amp; ASSUMED BACKGROUND This course is aimed at researchers and technical workers who are or will be analyzing scRNA-seq data. The material is suitable both for experimentalists who want to learn more about data-analysis as well as computational biologists who want to learn about scRNASeq methods. Examples demonstrated in this course can be applied to any experimental protocol or biological system. The requirements for this course are: 1. Working knowledge of unix (managing files, running programs) 2. Programming experience in R (writing a function, basic I/O operations, variable types, using packages). Bioconductor experience is a plus. 3. Familiarity with next-generation sequencing data and its analyses (using alignment and quantification tools for bulk sequencing data) 1.3 COURSE FORMAT The course will be delivered over the course of five days. Each day will include a lecture and laboratory component. The lecture will introduce the topics of discussion and the laboratory sessions will be focused on practical hands-on analysis of scRNA-seq data. These sessions will involve a combination of both mirroring exercises with the instructor to demonstrate a skill as well as applying these skills on your own to complete individual exercises. After and during each exercise, interpretation of results will be discussed as a group. Computing will be done using a combination of tools installed on the attendees laptop computer and web resources accessed via web browser. 1.4 Getting Started 1.5 SESSION CONTENT 1.5.1 Monday – Classes from 09:30 to 17:30 (lunch break-1 hr, 40 min of total coffee breaks) 1.5.1.1 Lecture 1 – scRNA-Seq experimental design (1 hour, Orr) Overview of course (intros, 20 min) General introduction: HCA/KCO overview Comparison of Bulk and single cell RNA-Seq Overview of available scRNA-seq technologies (10x) and experimental protocols scRNA-Seq experimental design and analysis workflow? 1.5.1.2 Lab 1 – Understanding sequencing raw data (Kirk, 1.5-2 hours) Lab based around data wrangling from public data repositories: get data from 10x website, single cell portal, from GEO (fastqs, counts) Shell and Unix commands to navigate directories, create folders, open files Raw file formats 1.5.1.3 Lecture 2 - Intro to Data processing: from bcl file to bam file (1 hour, Dana) scRNA-Seq processing workflow starting with choice of sequencer (NextSeq, HiSeq, MiSeq) / barcode swapping and bcl files Overview of Popular tools and algorithms Common single-cell analyses and interpretation Sequencing data: alignment and quality control Looking at cool things in alignment like where reads are, mutations, splicing 1.5.1.4 Lab 2 – Processing raw scRNA-Seq data (Dana, no R at this point) Data outputs from different scRNAseq technologies (10x, Smart-seq2) - process both? Demultiplexing sequencing data Read Quality Control (CellRanger, dropEst, fastqc) Run bowtie2 on 2 wells to demonstrate alignment Read alignment and visualization (kallisto, RSEM, Igviewer) http://hemberg-lab.github.io/scRNA.seq.course/processing-raw-scrna-seq-data.html Chapters 3 and 4? Are there parts that supposed to be in labs 1 or 3? Demultiplexing FastQC Align (STAR/TOPHAT/Kallisto) IGViewer - what do we want here? I use it for mutation detections, copying sequences, searching for alternative splicing. Flash talks (1.5 hr, break into 2 groups of 13) small presentation about your genome assembly and annotation project, ideally do 3 slides -2/3 mins (powerpoint or similar). So you can introduce yourselves and we can get to know each other. 1.5.2 Tuesday – Classes from 09:30 to 17:30 1.5.2.1 Lecture 3 – Transcriptome quantification: from bam file to counts (Orr) Read &amp; UMI counting (Kallisto alignment-free pseudocounts as well), how RSEM works (length dependence, sequencing depth, multimapping reads), CellRanger (dropest), bustools 10x barcode structure and links to Perturb-seq Gene length &amp; coverage Gene expression units (count data Smart-seq2 counts or 10x UMIs vs expression data) Some R overview slides, https://r4ds.had.co.nz/ 1.5.2.2 Lab 3 - Introduction to R (Kirk) Installing packages Data-types Data manipulation, slicing Strings manipulations Introducing object oriented programming / S4 objects Visualization tools Bonus create FeaturePlot from Seurat in base ggplot Bonus: run RSEM on Dana’s bam files if you are bored 1.5.2.3 Lecture 4 - Expression QC, normalisation and batch correction (Dana) What CellRanger does for quality filtering PBMC data normalisation methods https://www.nature.com/articles/nmeth.4292 Doublets, empty droplets Barcode swapping Regression with technical covariates What about imputation? 1.5.2.4 Lab 4 – Data wrangling for scRNAseq data (Dana) Data structures and file formats for single-cell data Quality control of cells and genes (doublets, ambient, empty drops) Data exploration: violin plots… Introducing Seurat object Genes House keeping genes Mitochondrial genes (never used these ones) Filter - Do we remove both cells and genes here? Normalize (introduce more options, other than log transform?) Find variable genes (Is it a first reduction? Why the binning?) Scaling Regression Heatmap of desired genes? Sigantures? http://hemberg-lab.github.io/scRNA.seq.course/introduction-to-rbioconductor.html 9.1 - 9.5? Bonus - imputation (magic? One of the two Gocken recommended?) Flash talks (1.5 hr, break into 2 groups of 13) small presentation about your genome assembly and annotation project, ideally do 3 slides -2/3 mins (powerpoint or similar). So you can introduce yourselves and we can get to know each other. 1.5.3 Wednesday – Classes from 09:30 to 17:30 1.5.3.1 Lecture 5 - Identifying cell populations (Kirk) Feature selection Dimensionality reduction Clustering and assigning identity (Louvain, NMF, topic models, variational autoencoder) Differential expression tests 1.5.3.2 Lab 5 – Feature selection &amp; Clustering analysis (Kirk) Parameters and clustering Comparison of feature selection methods 1.5.3.3 Lecture 6 - Introduction to batch effects (Orr) Batch correction methods (regress out batch, scaling within batch, CCA, MNN, Liger, scvi, scgen) Evaluation methods for batch correction (ARI, average silhouette width, kBET…) 1.5.3.4 Lab 6 - Correcting batch effects (Orr) Comparison of batch correction methods, Seurat pancreas Poster session with beer &amp; wine (time?) poster of current or proposed single cell genomic study. Print out would be good (recent posters are fine), or if you haven’t got a recent one, just a quick one pulled together on powerpoint and printed out on A4 is okay too - you shouldn’t stress too much about this, it’s just to connect the flash talks to the posters and it will be absolutely informal (unlike a poster session at a conference!). Take notes on how to do single-cell analysis, ideas, challenges, things you find interesting, directions you would like to explore. 1.5.4 Thursday – Classes from 09:30 to 17:30 Post poster session discussion groups 30 min discussion wrapping up poster session, and keeping track of ideas in a shared Google doc 1.5.4.1 Lecture 7 - Advanced topics: Functional analysis of cell sub-populations (Kirk 30 min) Gene sets and signatures Pathway analysis inferCNV / honeybadger 1.5.4.2 Lecture 7 - Advanced topics: Pseudotime cell trajectories (Kirk 30 min) Waddington Landscape Pseudotime inference Differential expression through pseudotime Lecture 7 - Advanced topics: Spatial genomics, multiplexing? (Kirk 30 min) 1.5.4.3 Lab 8 - Functional and Pseudotime analysis (Orr) Popular tools and packages for functional analysis (https://github.com/dynverse/dynmethods#list-of-included-methods) Review concepts from papers Comparison of pseudotime methods https://github.com/velocyto-team/velocyto.R 1.5.4.4 Lecture 8 - Single-cell multiomic technologies (Dana) Introduction to other omic data types Integrating scRNA-seq with other single-cell modalities (CITE, Perturb, ATAC, methylation…) 1.5.4.5 Lab 9 - Analysis of CITE-seq, scATAC-seq (Orr, may be time-limited) https://github.com/Hoohm/CITE-seq-Count https://cite-seq.com/eccite-seq/ https://support.10xgenomics.com/single-cell-vdj/index/doc/technical-note-assay-scheme-and-configuration-of-chromium-single-cell-vdj-libraries https://satijalab.org/seurat/multimodal_vignette.html https://www.bioconductor.org/packages/devel/bioc/vignettes/cicero/inst/doc/website.html 1.5.5 Friday – Classes from 09:30 to 17:30 1.5.5.1 Lab 10 - small dataset for analysis (Dana) Karthik has a good starting point: Krumlov_lab2_guidelines.html and Hemberg lab http://hemberg-lab.github.io/scRNA.seq.course/advanced-exercises.html Present a set of methods and orders in which to try them IDH mutated glioma Goal for first half: get to clustering and identify malignant cells (inferCNV possible) Goal for second half: cell states For our other courses, the last day we usually divide them in groups of 3-4 ppl and assign them a small dataset in order to repeat all the analyses they have learnt during the week, to think about the best strategy to carry out the analyses and to present the results in front of the other ppl. I believe this is something very productive and helpful because it is a kind of wrap-up and brainstorming session. Normally, ppl love to talk and present something and in this way they/we can be 100% sure they really understood the different steps of the pipeline. Lecture 9 - Group presentations Review, Questions and Answers "],
["scrna-seq-experimental-design.html", "2 scRNA-Seq Experimental Design", " 2 scRNA-Seq Experimental Design "],
["understanding-sequencing-raw-data.html", "3 Understanding Sequencing Raw Data 3.1 Class Environment 3.2 Shell and Unix commands 3.3 File formats 3.4 Public data repositories", " 3 Understanding Sequencing Raw Data 3.1 Class Environment 3.1.1 Getting into AWS Instance ## Example ssh -i berlin.pem ubuntu@&lt;PUBLIC IP ADDRESS&gt; (e.g.34.219.254.245) ## Actual Command ssh i berlin.pem ubuntu@34.213.180.241 3.1.2 Rstudio 3.2 Shell and Unix commands 3.2.1 Common Linux Commands 3.2.1.1 Lab 1a check the your present directory pwd make a directory called data mkdir data change into data directory check manual page of wget command redirect wget maunual page output into a file called wget.txt return the lines that contain output in the wget.txt file Compress wget.txt file View Compressed file 3.2.1.2 Docker Commands ## maybe take away the --rm so they can save the container for later sudo docker run --rm -it -v $PWD/Share:/Share kdgosik/scellbern2019 bash Explaination of commands - docker: command to run docker - run: asking docker to run a container - –rm: flag to remove the container when you exit from it - nothing will be saved from your session to access again later - this flag can be removed to keep container - -it: flag to run the container interactively - this will keep all session output displaying on the terminal - to stop container go to terminal and press Crtl+c - kdgosik/scellbern2019: the image to run. It will be the image into a container if not already built on your computer - image link 3.3 File formats bcl fastq bam mtx, tsv hdf5 (.h5, .h5ad) 3.4 Public data repositories 3.4.1 Cellranger/10x 3.4.1.1 Lab 1b 10x PBMC data are hosted in https://s3-us-west-2.amazonaws.com/10x.files/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz change directory into the data directory get 10x PBMC data unzip data explore directory explore files 3.4.2 GEO https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE81905 3.4.2.1 Lab 1c Get GEO Data - ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE81nnn/GSE81905/matrix/GSE81905-GPL19057_series_matrix.txt.gz - ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE81nnn/GSE81905/matrix/GSE81905-GPL17021_series_matrix.txt.gz make a directory for the files or use data directory go into that directory get files and place them in the directory View files (try keeping in compressed format and view that way) 3.4.3 Single Cell Portal https://portals.broadinstitute.org/single_cell Study: Salk Institute - Single-cell Methylome Sequencing Identifies Distinct Neuronal Populations in Mouse Frontal Cortex 3.4.3.1 Lab 1d Get R2 fastq file from the Salk Institute study Look at files 3.4.3.2 Lab 1e Get Docker on your local computer for you to have Explore Single Cell Portal Explore GEO "],
["data-preprocessing.html", "4 Data Preprocessing", " 4 Data Preprocessing "],
["processing-scrna-seq-data.html", "5 Processing scRNA-Seq data", " 5 Processing scRNA-Seq data "],
["transcriptome-quantification.html", "6 Transcriptome Quantification", " 6 Transcriptome Quantification "],
["introduction-rbioconductor.html", "7 Introduction R/Bioconductor 7.1 Installing packages 7.2 Installation instructions: 7.3 Data-types/classes 7.4 Basic data structures 7.5 More information 7.6 Bioconductor S4 Classes 7.7 Grammer of Graphics (ggplot2)", " 7 Introduction R/Bioconductor Presentation R/Rstudio parts Data Types and classes Packages and where to get them S3 vs S4 Visualizations and ggplot 7.1 Installing packages 7.1.1 CRAN The Comprehensive R Archive Network CRAN is the biggest archive of R packages. There are few requirements for uploading packages besides building and installing succesfully, hence documentation and support is often minimal and figuring how to use these packages can be a challenge it itself. CRAN is the default repository R will search to find packages to install: install.packages(&quot;devtools&quot;) require(&quot;devtools&quot;) 7.1.2 Github Github isn’t specific to R, any code of any type in any state can be uploaded. There is no guarantee a package uploaded to github will even install, nevermind do what it claims to do. R packages can be downloaded and installed directly from github using the “devtools” package installed above. devtools::install_github(&quot;tallulandrews/M3Drop&quot;) Github is also a version control system which stores multiple versions of any package. By default the most recent “master” version of the package is installed. If you want an older version or the development branch this can be specified using the “ref” parameter: # different branch devtools::install_github(&quot;tallulandrews/M3D&quot;, ref=&quot;nbumi&quot;) # previous commit devtools::install_github(&quot;tallulandrews/M3Drop&quot;, ref=&quot;434d2da28254acc8de4940c1dc3907ac72973135&quot;) Note: make sure you re-install the M3Drop master branch for later in the course. 7.1.3 Bioconductor Bioconductor is a repository of R-packages specifically for biological analyses. It has the strictest requirements for submission, including installation on every platform and full documentation with a tutorial (called a vignette) explaining how the package should be used. Bioconductor also encourages utilization of standard data structures/classes and coding style/naming conventions, so that, in theory, packages and analyses can be combined into large pipelines or workflows. Bioconductor also requires creators to support their packages and has a regular 6-month release schedule. Make sure you are using the most recent release of bioconductor before trying to install packages for the course. ## &gt;= R 3.5.0 if (!requireNamespace(&quot;BiocManager&quot;, quietly = TRUE)) install.packages(&quot;BiocManager&quot;) BiocManager::install(&quot;MAST&quot;, version = &quot;3.8&quot;) 7.1.4 Source The final way to install packages is directly from source. In this case you have to download a fully built source code file, usually packagename.tar.gz, or clone the github repository and rebuild the package yourself. Generally this will only be done if you want to edit a package yourself, or if for some reason the former methods have failed. install.packages(&quot;M3Drop_3.05.00.tar.gz&quot;, type=&quot;source&quot;) 7.2 Installation instructions: All the packages necessary for this course are available here. Starting from “RUN Rscript -e”install.packages(‘devtools’)&quot; “, run each of the commands (minus”RUN“) on the command line or start an R session and run each of the commands within the quotation marks. Note the ordering of the installation is important in some cases, so make sure you run them in order from top to bottom. 7.3 Data-types/classes R is a high level language so the underlying data-type is generally not important. The exception if you are accessing R data directly using another language such as C, but that is beyond the scope of this course. Instead we will consider the basic data classes: numeric, integer, logical, and character, and the higher level data class called “factor”. You can check what class your data is using the “class()” function. Aside: R can also store data as “complex” for complex numbers but generally this isn’t relevant for biological analyses. 7.3.1 Numeric The “numeric” class is the default class for storing any numeric data - integers, decimal numbers, numbers in scientific notation, etc… x = 1.141 class(x) ## [1] &quot;numeric&quot; y = 42 class(y) ## [1] &quot;numeric&quot; z = 6.02e23 class(z) ## [1] &quot;numeric&quot; Here we see that even though R has an “integer” class and 42 could be stored more efficiently as an integer the default is to store it as “numeric”. If we want 42 to be stored as an integer we must “coerce” it to that class: y = as.integer(42) class(y) ## [1] &quot;integer&quot; Coercion will force R to store data as a particular class, if our data is incompatible with that class it will still do it but the data will be converted to NAs: as.numeric(&quot;H&quot;) ## Warning: NAs introduced by coercion ## [1] NA Above we tried to coerce “character” data, identified by the double quotation marks, into numeric data which doesn’t make sense, so we triggered (“threw”) an warning message. Since this is only a warning R would continue with any subsequent commands in a script/function, whereas an “error” would cause R to halt. 7.3.2 Character/String The “character” class stores all kinds of text data. Programing convention calls data containing multiple letters a “string”, thus most R functions which act on character data will refer to the data as “strings” and will often have “str” or “string” in it’s name. Strings are identified by being flanked by double quotation marks, whereas variable/function names are not: x = 5 a = &quot;x&quot; # character &quot;x&quot; a ## [1] &quot;x&quot; b = x # variable x b ## [1] 5 In addition to standard alphanumeric characters, strings can also store various special characters. Special characters are identified using a backlash followed by a single character, the most relevant are the special character for tab : \\t and new line : \\n. To demonstrate the these special characters lets concatenate (cat) together two strings with these characters separating (sep) them: cat(&quot;Hello&quot;, &quot;World&quot;, sep= &quot; &quot;) ## Hello World cat(&quot;Hello&quot;, &quot;World&quot;, sep= &quot;\\t&quot;) ## Hello World cat(&quot;Hello&quot;, &quot;World&quot;, sep= &quot;\\n&quot;) ## Hello ## World Note that special characters work differently in different functions. For instance the paste function does the same thing as cat but does not recognize special characters. paste(&quot;Hello&quot;, &quot;World&quot;, sep= &quot; &quot;) ## [1] &quot;Hello World&quot; paste(&quot;Hello&quot;, &quot;World&quot;, sep= &quot;\\t&quot;) ## [1] &quot;Hello\\tWorld&quot; paste(&quot;Hello&quot;, &quot;World&quot;, sep= &quot;\\n&quot;) ## [1] &quot;Hello\\nWorld&quot; Single or double backslash is also used as an escape character to turn off special characters or allow quotation marks to be included in strings: cat(&quot;This \\&quot;string\\&quot; contains quotation marks.&quot;) ## This &quot;string&quot; contains quotation marks. Special characters are generally only used in pattern matching, and reading/writing data to files. For instance this is how you would read a tab-separated file into R. dat = read.delim(&quot;file.tsv&quot;, sep=&quot;\\t&quot;) Another special type of character data are colours. Colours can be specified in three main ways: by name from those available, by red, green, blue values using the rgb function, and by hue (colour), saturation (colour vs white) and value (colour/white vs black) using the hsv function. By default rgb and hsv expect three values in 0-1 with an optional fourth value for transparency. Alternatively, sets of predetermined colours with useful properties can be loaded from many different packages with RColorBrewer being one of the most popular. reds = c(&quot;red&quot;, rgb(1,0,0), hsv(0, 1, 1)) reds ## [1] &quot;red&quot; &quot;#FF0000&quot; &quot;#FF0000&quot; barplot(c(1,1,1), col=reds, names=c(&quot;by_name&quot;, &quot;by_rgb&quot;, &quot;by_hsv&quot;)) 7.3.3 Logical The logical class stores boolean truth values, i.e. TRUE and FALSE. It is used for storing the results of logical operations and conditional statements will be coerced to this class. Most other data-types can be coerced to boolean without triggering (or “throwing”) error messages, which may cause unexpected behaviour. x = TRUE class(x) ## [1] &quot;logical&quot; y = &quot;T&quot; as.logical(y) ## [1] TRUE z = 5 as.logical(z) ## [1] TRUE x = FALSE class(x) ## [1] &quot;logical&quot; y = &quot;F&quot; as.logical(y) ## [1] FALSE z = 0 as.logical(z) ## [1] FALSE Exercise 1 Experiment with other character and numeric values, which are coerced to TRUE or FALSE? which are coerced to neither? Do you ever throw a warning/error message? 7.3.4 Factors String/Character data is very memory inefficient to store, each letter generally requires the same amount of memory as any integer. Thus when storing a vector of strings with repeated elements it is more efficient assign each element to an integer and store the vector as integers and an additional string-to-integer association table. Thus, by default R will read in text columns of a data table as factors. str_vector = c(&quot;Apple&quot;, &quot;Apple&quot;, &quot;Banana&quot;, &quot;Banana&quot;, &quot;Banana&quot;, &quot;Carrot&quot;, &quot;Carrot&quot;, &quot;Apple&quot;, &quot;Banana&quot;) factored_vector = factor(str_vector) factored_vector ## [1] Apple Apple Banana Banana Banana Carrot Carrot Apple Banana ## Levels: Apple Banana Carrot as.numeric(factored_vector) ## [1] 1 1 2 2 2 3 3 1 2 The double nature of factors can cause some unintuitive behaviour. E.g. joining two factors together will convert them to the numeric form and the original strings will be lost. c(factored_vector, factored_vector) ## [1] 1 1 2 2 2 3 3 1 2 1 1 2 2 2 3 3 1 2 Likewise if due to formatting issues numeric data is mistakenly interpretted as strings, then you must convert the factor back to strings before coercing to numeric values: x = c(&quot;20&quot;, &quot;25&quot;, &quot;23&quot;, &quot;38&quot;, &quot;20&quot;, &quot;40&quot;, &quot;25&quot;, &quot;30&quot;) x = factor(x) as.numeric(x) ## [1] 1 3 2 5 1 6 3 4 as.numeric(as.character(x)) ## [1] 20 25 23 38 20 40 25 30 To make R read text as character data instead of factors set the environment option stringsAsFactors=FALSE. This must be done at the start of each R session. options(stringsAsFactors=FALSE) Exercise How would you use factors to create a vector of colours for an arbitrarily long vector of fruits like str_vector above? Answer 7.3.5 Checking class/type We recommend checking your data is of the correct class after reading from files: x = 1.4 is.numeric(x) ## [1] TRUE is.character(x) ## [1] FALSE is.logical(x) ## [1] FALSE is.factor(x) ## [1] FALSE 7.4 Basic data structures So far we have only looked at single values and vectors. Vectors are the simplest data structure in R. They are a 1-dimensional array of data all of the same type. If the input when creating a vector is of different types it will be coerced to the data-type that is most consistent with the data. x = c(&quot;Hello&quot;, 5, TRUE) x ## [1] &quot;Hello&quot; &quot;5&quot; &quot;TRUE&quot; class(x) ## [1] &quot;character&quot; Here we tried to put character, numeric and logical data into a single vector so all the values were coerced to character data. A matrix is the two dimensional version of a vector, it also requires all data to be of the same type. If we combine a character vector and a numeric vector into a matrix, all the data will be coerced to characters: x = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;) y = c(1, 2, 3) class(x) ## [1] &quot;character&quot; class(y) ## [1] &quot;numeric&quot; m = cbind(x, y) m ## x y ## [1,] &quot;A&quot; &quot;1&quot; ## [2,] &quot;B&quot; &quot;2&quot; ## [3,] &quot;C&quot; &quot;3&quot; The quotation marks indicate that the numeric vector has been coerced to characters. Alternatively, to store data with columns of different data-types we can use a dataframe. z = data.frame(x, y) z ## x y ## 1 A 1 ## 2 B 2 ## 3 C 3 class(z[,1]) ## [1] &quot;character&quot; class(z[,2]) ## [1] &quot;numeric&quot; If you have set stringsAsFactors=FALSE as above you will find the first column remains characters, otherwise it will be automatically converted to a factor. options(stringsAsFactors=TRUE) z = data.frame(x, y) class(z[,1]) ## [1] &quot;factor&quot; Another difference between matrices and dataframes is the ability to select columns using the $ operator: m$x # throws an error z$x # ok The final basic data structure is the list. Lists allow data of different types and different lengths to be stored in a single object. Each element of a list can be any other R object : data of any type, any data structure, even other lists or functions. l = list(m, z) ll = list(sublist=l, a_matrix=m, numeric_value=42, this_string=&quot;Hello World&quot;, even_a_function=cbind) ll ## $sublist ## $sublist[[1]] ## x y ## [1,] &quot;A&quot; &quot;1&quot; ## [2,] &quot;B&quot; &quot;2&quot; ## [3,] &quot;C&quot; &quot;3&quot; ## ## $sublist[[2]] ## x y ## 1 A 1 ## 2 B 2 ## 3 C 3 ## ## ## $a_matrix ## x y ## [1,] &quot;A&quot; &quot;1&quot; ## [2,] &quot;B&quot; &quot;2&quot; ## [3,] &quot;C&quot; &quot;3&quot; ## ## $numeric_value ## [1] 42 ## ## $this_string ## [1] &quot;Hello World&quot; ## ## $even_a_function ## function (..., deparse.level = 1) ## .Internal(cbind(deparse.level, ...)) ## &lt;bytecode: 0x102bae238&gt; ## &lt;environment: namespace:base&gt; Lists are most commonly used when returning a large number of results from a function that do not fit into any of the previous data structures. 7.5 More information You can get more information about any R commands relevant to these datatypes using by typing ?function in an interactive session. 7.6 Bioconductor S4 Classes Introduction Object-Oriented Programming in R Role of S4 in Bioconductor S4 Basics S4 Classes S4 Generic Functions &amp; Methods S4 Exercises S4 Constraints Copy on Slot Modification Object Overhead Method Dispatch S4 Case Studies Slot-Oriented Virtual Class (eSet) Method-Oriented Virtual Class (Sequence) Multiple Inheritance &amp; Vectorization (CompressedIRangesList) Build or Reuse? (CompresssedIRangesList) Class Union &amp; Group Generic (Rle) 7.6.1 S4 Basics 7.6.2 S4 Case Studies 7.6.3 S4 Exercises 7.7 Grammer of Graphics (ggplot2) 7.7.1 What is ggplot2? ggplot2 is an R package designed by Hadley Wickham which facilitates data plotting. In this lab, we will touch briefly on some of the features of the package. If you would like to learn more about how to use ggplot2, we would recommend reading “ggplot2 Elegant graphics for data analysis”, by Hadley Wickham. 7.7.2 Principles of ggplot2 Your data must be a dataframe if you want to plot it using ggplot2. Use the aes mapping function to specify how variables in the dataframe map to features on your plot Use geoms to specify how your data should be represented on your graph eg. as a scatterplot, a barplot, a boxplot etc. 7.7.3 Using the aes mapping function The aes function specifies how variables in your dataframe map to features on your plot. To understand how this works, let’s look at an example: library(ggplot2) library(tidyverse) set.seed(1) counts &lt;- as.data.frame(matrix(rpois(100, lambda = 10), ncol=10, nrow=10)) Gene_ids &lt;- paste(&quot;gene&quot;, 1:10, sep = &quot;&quot;) colnames(counts) &lt;- paste(&quot;cell&quot;, 1:10, sep = &quot;&quot;) counts&lt;-data.frame(Gene_ids, counts) counts ## Gene_ids cell1 cell2 cell3 cell4 cell5 cell6 cell7 cell8 cell9 cell10 ## 1 gene1 8 8 3 5 5 9 11 9 13 6 ## 2 gene2 10 2 11 13 12 12 7 13 12 15 ## 3 gene3 7 8 13 8 9 9 9 5 15 12 ## 4 gene4 11 10 7 13 12 12 12 8 11 12 ## 5 gene5 14 7 8 9 11 10 13 13 5 11 ## 6 gene6 12 12 11 15 8 7 10 9 10 15 ## 7 gene7 11 11 14 11 11 5 9 13 13 7 ## 8 gene8 9 12 9 8 6 14 7 12 12 10 ## 9 gene9 14 12 11 7 10 10 8 14 7 10 ## 10 gene10 11 10 9 7 11 16 8 7 7 4 ggplot(data = counts, mapping = aes(x = cell1, y = cell2)) Let’s take a closer look at the final command, ggplot(data = counts, mapping = aes(x = cell1, y = cell2)). ggplot() initialises a ggplot object and takes the arguments data and mapping. We pass our dataframe of counts to data and use the aes() function to specify that we would like to use the variable cell1 as our x variable and the variable cell2 as our y variable. Task 1: Modify the command above to initialise a ggplot object where cell10 is the x variable and cell8 is the y variable. Clearly, the plots we have just created are not very informative because no data is displayed on them. To display data, we will need to use geoms. 7.7.4 Geoms We can use geoms to specify how we would like data to be displayed on our graphs. For example, our choice of geom could specify that we would like our data to be displayed as a scatterplot, a barplot or a boxplot. Let’s see how our graph would look as a scatterplot. ggplot(data = counts, mapping = aes(x = cell1, y = cell2)) + geom_point() Now we can see that there doesn’t seem to be any correlation between gene expression in cell1 and cell2. Given we generated counts randomly, this isn’t too surprising. Task 2: Modify the command above to create a line plot. Hint: execute ?ggplot and scroll down the help page. At the bottom is a link to the ggplot package index. Scroll through the index until you find the geom options. 7.7.5 Plotting data from more than 2 cells So far we’ve been considering the gene counts from 2 of the cells in our dataframe. But there are actually 10 cells in our dataframe and it would be nice to compare all of them. What if we wanted to plot data from all 10 cells at the same time? At the moment we can’t do this because we are treating each individual cell as a variable and assigning that variable to either the x or the y axis. We could create a 10 dimensional graph to plot data from all 10 cells on, but this is a) not possible to do with ggplot and b) not very easy to interpret. What we could do instead is to tidy our data so that we had one variable representing cell ID and another variable representing gene counts, and plot those against each other. In code, this would look like: counts&lt;-gather(counts, colnames(counts)[2:11], key = &#39;Cell_ID&#39;, value=&#39;Counts&#39;) head(counts) ## Gene_ids Cell_ID Counts ## 1 gene1 cell1 8 ## 2 gene2 cell1 10 ## 3 gene3 cell1 7 ## 4 gene4 cell1 11 ## 5 gene5 cell1 14 ## 6 gene6 cell1 12 Essentially, the problem before was that our data was not tidy because one variable (Cell_ID) was spread over multiple columns. Now that we’ve fixed this problem, it is much easier for us to plot data from all 10 cells on one graph. ggplot(counts,aes(x=Cell_ID, y=Counts)) + geom_boxplot() Task 3: Use the updated counts dataframe to plot a barplot with Cell_ID as the x variable and Counts as the y variable. Hint: you may find it helpful to read ?geom_bar. Task 4: Use the updated counts dataframe to plot a scatterplot with Gene_ids as the x variable and Counts as the y variable. 7.7.6 Plotting heatmaps A common method for visualising gene expression data is with a heatmap. Here we will use the R package pheatmap to perform this analysis with some gene expression data we will name test. library(pheatmap) set.seed(2) test = matrix(rnorm(200), 20, 10) test[1:10, seq(1, 10, 2)] = test[1:10, seq(1, 10, 2)] + 3 test[11:20, seq(2, 10, 2)] = test[11:20, seq(2, 10, 2)] + 2 test[15:20, seq(2, 10, 2)] = test[15:20, seq(2, 10, 2)] + 4 colnames(test) = paste(&quot;Cell&quot;, 1:10, sep = &quot;&quot;) rownames(test) = paste(&quot;Gene&quot;, 1:20, sep = &quot;&quot;) pheatmap(test) Let’s take a moment to work out what this graphic is showing us. Each row represents a gene and each column represents a cell. How highly expressed each gene is in each cell is represented by the colour of the corresponding box. For example, we can tell from this plot that gene18 is highly expressed in cell10 but lowly expressed in cell1. This plot also gives us information on the results of a clustering algorithm. In general, clustering algorithms aim to split datapoints (eg.cells) into groups whose members are more alike one another than they are alike the rest of the datapoints. The trees drawn on the top and left hand sides of the graph are the results of clustering algorithms and enable us to see, for example, that cells 4,8,2,6 and 10 are more alike one another than they are alike cells 7,3,5,1 and 9. The tree on the left hand side of the graph represents the results of a clustering algorithm applied to the genes in our dataset. If we look closely at the trees, we can see that eventually they have the same number of branches as there are cells and genes. In other words, the total number of cell clusters is the same as the total number of cells, and the total number of gene clusters is the same as the total number of genes. Clearly, this is not very informative, and will become impractical when we are looking at more than 10 cells and 20 genes. Fortunately, we can set the number of clusters we see on the plot. Let’s try setting the number of gene clusters to 2: pheatmap(test, kmeans_k = 2) Now we can see that the genes fall into two clusters - a cluster of 8 genes which are upregulated in cells 2, 10, 6, 4 and 8 relative to the other cells and a cluster of 12 genes which are downregulated in cells 2, 10, 6, 4 and 8 relative to the other cells. Task 5: Try setting the number of clusters to 3. Which number of clusters do you think is more informative? 7.7.7 Principal Component Analysis Principal component analysis (PCA) is a statistical procedure that uses a transformation to convert a set of observations into a set of values of linearly uncorrelated variables called principal components. The transformation is carried out so that the first principle component accounts for as much of the variability in the data as possible, and each following principle component accounts for the greatest amount of variance possible under the contraint that it must be orthogonal to the previous components. PCA plots are a good way to get an overview of your data, and can sometimes help identify confounders which explain a high amount of the variability in your data. We will investigate how we can use PCA plots in single-cell RNA-seq analysis in more depth in a future lab, here the aim is to give you an overview of what PCA plots are and how they are generated. Let’s make a PCA plot for our test data. We can use the ggfortify package to let ggplot know how to interpret principle components. library(ggfortify) Principal_Components&lt;-prcomp(test) autoplot(Principal_Components, label=TRUE) Task 6: Compare your clusters to the pheatmap clusters. Are they related? (Hint: have a look at the gene tree for the first pheatmap we plotted) Task 7: Produce a heatmap and PCA plot for counts (below): set.seed(1) counts &lt;- as.data.frame(matrix(rpois(100, lambda = 10), ncol=10, nrow=10)) rownames(counts) &lt;- paste(&quot;gene&quot;, 1:10, sep = &quot;&quot;) colnames(counts) &lt;- paste(&quot;cell&quot;, 1:10, sep = &quot;&quot;) "],
["expression-qc-and-normalization.html", "8 Expression QC and Normalization", " 8 Expression QC and Normalization "],
["data-wrangling-scrnaseq.html", "9 Data Wrangling scRNAseq", " 9 Data Wrangling scRNAseq "],
["identifying-cell-populations.html", "10 Identifying Cell Populations 10.1 Google Slides", " 10 Identifying Cell Populations 10.1 Google Slides "],
["feature-selection-and-cluster-analysis.html", "11 Feature Selection and Cluster Analysis 11.1 Abstract 11.2 Seurat Tutorial 11.3 Feature Selection", " 11 Feature Selection and Cluster Analysis 11.1 Abstract Many methods have been used to determine differential gene expression from single-cell RNA (scRNA)-seq data. We evaluated 36 approaches using experimental and synthetic data and found considerable differences in the number and characteristics of the genes that are called differentially expressed. Prefiltering of lowly expressed genes has important effects, particularly for some of the methods developed for bulk RNA-seq data analysis. However, we found that bulk RNA-seq analysis methods do not generally perform worse than those developed specifically for scRNA-seq. We also present conquer, a repository of consistently processed, analysis-ready public scRNA-seq data sets that is aimed at simplifying method evaluation and reanalysis of published results. Each data set provides abundance estimates for both genes and transcripts, as well as quality control and exploratory analysis reports. (Soneson and Robinson 2018) Cells are the basic building blocks of organisms and each cell is unique. Single-cell RNA sequencing has emerged as an indispensable tool to dissect the cellular heterogeneity and decompose tissues into cell types and/or cell states, which offers enormous potential for de novo discovery. Single-cell transcriptomic atlases provide unprecedented resolution to reveal complex cellular events and deepen our understanding of biological systems. In this review, we summarize and compare single-cell RNA sequencing technologies, that were developed since 2009, to facilitate a well-informed choice of method. The applications of these methods in different biological contexts are also discussed. We anticipate an ever-increasing role of single-cell RNA sequencing in biology with further improvement in providing spatial information and coupling to other cellular modalities. In the future, such biological findings will greatly benefit medical research. (Hedlund and Deng 2018) 11.2 Seurat Tutorial library(Seurat) pbmc &lt;- pbmc_small # The number of genes and UMIs (nGene and nUMI) are automatically calculated # for every object by Seurat. For non-UMI data, nUMI represents the sum of # the non-normalized values within a cell We calculate the percentage of # mitochondrial genes here and store it in percent.mito using AddMetaData. # We use object@raw.data since this represents non-transformed and # non-log-normalized counts The % of UMI mapping to MT-genes is a common # scRNA-seq QC metric. mito.genes &lt;- grep(pattern = &quot;^MT-&quot;, x = rownames(x = pbmc@data), value = TRUE) percent.mito &lt;- Matrix::colSums(pbmc@raw.data[mito.genes, ])/Matrix::colSums(pbmc@raw.data) # AddMetaData adds columns to object@meta.data, and is a great place to # stash QC stats pbmc &lt;- AddMetaData(object = pbmc, metadata = percent.mito, col.name = &quot;percent.mito&quot;) VlnPlot(object = pbmc, features.plot = c(&quot;nGene&quot;, &quot;nUMI&quot;, &quot;percent.mito&quot;), nCol = 3) # GenePlot is typically used to visualize gene-gene relationships, but can # be used for anything calculated by the object, i.e. columns in # object@meta.data, PC scores etc. Since there is a rare subset of cells # with an outlier level of high mitochondrial percentage and also low UMI # content, we filter these as well par(mfrow = c(1, 2)) GenePlot(object = pbmc, gene1 = &quot;nUMI&quot;, gene2 = &quot;percent.mito&quot;) GenePlot(object = pbmc, gene1 = &quot;nUMI&quot;, gene2 = &quot;nGene&quot;) # We filter out cells that have unique gene counts over 2,500 or less than # 200 Note that low.thresholds and high.thresholds are used to define a # &#39;gate&#39;. -Inf and Inf should be used if you don&#39;t want a lower or upper # threshold. pbmc &lt;- FilterCells(object = pbmc, subset.names = c(&quot;nGene&quot;, &quot;percent.mito&quot;), low.thresholds = c(200, -Inf), high.thresholds = c(2500, 0.05)) pbmc &lt;- NormalizeData(object = pbmc, normalization.method = &quot;LogNormalize&quot;, scale.factor = 10000) pbmc &lt;- FindVariableGenes(object = pbmc, mean.function = ExpMean, dispersion.function = LogVMR, x.low.cutoff = 0.0125, x.high.cutoff = 3, y.cutoff = 0.5) pbmc &lt;- ScaleData(object = pbmc, vars.to.regress = c(&quot;nUMI&quot;, &quot;percent.mito&quot;)) pbmc &lt;- RunPCA(object = pbmc, pc.genes = pbmc@var.genes, do.print = TRUE, pcs.print = 1:5, genes.print = 5) # Examine and visualize PCA results a few different ways PrintPCA(object = pbmc, pcs.print = 1:5, genes.print = 5, use.full = FALSE) VizPCA(object = pbmc, pcs.use = 1:2) PCAPlot(object = pbmc, dim.1 = 1, dim.2 = 2) # ProjectPCA scores each gene in the dataset (including genes not included # in the PCA) based on their correlation with the calculated components. # Though we don&#39;t use this further here, it can be used to identify markers # that are strongly correlated with cellular heterogeneity, but may not have # passed through variable gene selection. The results of the projected PCA # can be explored by setting use.full=T in the functions above pbmc &lt;- ProjectPCA(object = pbmc, do.print = FALSE) PCHeatmap(object = pbmc, pc.use = 1, cells.use = 500, do.balanced = TRUE, label.columns = FALSE) PCHeatmap(object = pbmc, pc.use = 1:12, cells.use = 500, do.balanced = TRUE, label.columns = FALSE, use.full = FALSE) # NOTE: This process can take a long time for big datasets, comment out for # expediency. More approximate techniques such as those implemented in # PCElbowPlot() can be used to reduce computation time pbmc &lt;- JackStraw(object = pbmc, num.replicate = 100, display.progress = FALSE) JackStrawPlot(object = pbmc, PCs = 1:12) PCElbowPlot(object = pbmc) # save.SNN = T saves the SNN so that the clustering algorithm can be rerun # using the same graph but with a different resolution value (see docs for # full details) pbmc &lt;- FindClusters(object = pbmc, reduction.type = &quot;pca&quot;, dims.use = 1:10, resolution = 0.6, print.output = 0, save.SNN = TRUE) pbmc &lt;- RunTSNE(object = pbmc, dims.use = 1:10, do.fast = TRUE) # note that you can set do.label=T to help label individual clusters TSNEPlot(object = pbmc) # find all markers of cluster 1 cluster1.markers &lt;- FindMarkers(object = pbmc, ident.1 = 1, min.pct = 0.25) print(x = head(x = cluster1.markers, n = 5)) # find all markers distinguishing cluster 5 from clusters 0 and 3 cluster5.markers &lt;- FindMarkers(object = pbmc, ident.1 = 5, ident.2 = c(0, 3), min.pct = 0.25) print(x = head(x = cluster5.markers, n = 5)) # find all markers distinguishing cluster 5 from clusters 0 and 3 cluster5.markers &lt;- FindMarkers(object = pbmc, ident.1 = 5, ident.2 = c(0, 3), min.pct = 0.25) print(x = head(x = cluster5.markers, n = 5)) # find markers for every cluster compared to all remaining cells, report # only the positive ones pbmc.markers &lt;- FindAllMarkers(object = pbmc, only.pos = TRUE, min.pct = 0.25, thresh.use = 0.25) pbmc.markers %&gt;% group_by(cluster) %&gt;% top_n(2, avg_logFC) cluster1.markers &lt;- FindMarkers(object = pbmc, ident.1 = 0, thresh.use = 0.25, test.use = &quot;roc&quot;, only.pos = TRUE) VlnPlot(object = pbmc, features.plot = c(&quot;MS4A1&quot;, &quot;CD79A&quot;))s # you can plot raw UMI counts as well VlnPlot(object = pbmc, features.plot = c(&quot;NKG7&quot;, &quot;PF4&quot;), use.raw = TRUE, y.log = TRUE) FeaturePlot(object = pbmc, features.plot = c(&quot;MS4A1&quot;, &quot;GNLY&quot;, &quot;CD3E&quot;, &quot;CD14&quot;, &quot;FCER1A&quot;, &quot;FCGR3A&quot;, &quot;LYZ&quot;, &quot;PPBP&quot;, &quot;CD8A&quot;), cols.use = c(&quot;grey&quot;, &quot;blue&quot;), sreduction.use = &quot;tsne&quot;) top10 &lt;- pbmc.markers %&gt;% group_by(cluster) %&gt;% top_n(10, avg_logFC) # setting slim.col.label to TRUE will print just the cluster IDS instead of # every cell name DoHeatmap(object = pbmc, genes.use = top10$gene, slim.col.label = TRUE, remove.key = TRUE) current.cluster.ids &lt;- c(0, 1, 2, 3, 4, 5, 6, 7) new.cluster.ids &lt;- c(&quot;CD4 T cells&quot;, &quot;CD14+ Monocytes&quot;, &quot;B cells&quot;, &quot;CD8 T cells&quot;, &quot;FCGR3A+ Monocytes&quot;, &quot;NK cells&quot;, &quot;Dendritic cells&quot;, &quot;Megakaryocytes&quot;) pbmc@ident &lt;- plyr::mapvalues(x = pbmc@ident, from = current.cluster.ids, to = new.cluster.ids) TSNEPlot(object = pbmc, do.label = TRUE, pt.size = 0.5) 11.2.0.1 Further subdivisions within cell types If you perturb some of our parameter choices above (for example, setting resolution=0.8 or changing the number of PCs), you might see the CD4 T cells subdivide into two groups. You can explore this subdivision to find markers separating the two T cell subsets. However, before reclustering (which will overwrite object@ident), we can stash our renamed identities to be easily recovered later. # First lets stash our identities for later pbmc &lt;- StashIdent(object = pbmc, save.name = &quot;ClusterNames_0.6&quot;) # Note that if you set save.snn=T above, you don&#39;t need to recalculate the # SNN, and can simply put: pbmc &lt;- FindClusters(pbmc,resolution = 0.8) pbmc &lt;- FindClusters(object = pbmc, reduction.type = &quot;pca&quot;, dims.use = 1:10, resolution = 0.8, print.output = FALSE) ## Warning in BuildSNN(object = object, genes.use = genes.use, reduction.type ## = reduction.type, : Build parameters exactly match those of already ## computed and stored SNN. To force recalculation, set force.recalc to TRUE. # Demonstration of how to plot two tSNE plots side by side, and how to color # points based on different criteria plot1 &lt;- TSNEPlot(object = pbmc, do.return = TRUE, no.legend = TRUE, do.label = TRUE) plot2 &lt;- TSNEPlot(object = pbmc, do.return = TRUE, group.by = &quot;ClusterNames_0.6&quot;, no.legend = TRUE, do.label = TRUE) plot_grid(plot1, plot2) # Find discriminating markers tcell.markers &lt;- FindMarkers(object = pbmc, ident.1 = 0, ident.2 = 1) # Most of the markers tend to be expressed in C1 (i.e. S100A4). However, we # can see that CCR7 is upregulated in C0, strongly indicating that we can # differentiate memory from naive CD4 cells. cols.use demarcates the color # palette from low to high expression FeaturePlot(object = pbmc, features.plot = c(&quot;S100A4&quot;, &quot;CCR7&quot;), cols.use = c(&quot;green&quot;, &quot;blue&quot;)) 11.3 Feature Selection 11.3.1 Differential Expression / Variable Genes 11.3.1.1 Variable Genes pbmc &lt;- FindVariableGenes(object = pbmc, mean.function = ExpMean, dispersion.function = LogVMR, x.low.cutoff = 0.0125, x.high.cutoff = 3, y.cutoff = 0.5) VariableGenePlot(object, do.text = TRUE, cex.use = 0.5, cex.text.use = 0.5, do.spike = FALSE, pch.use = 16, col.use = &quot;black&quot;, spike.col.use = &quot;red&quot;, plot.both = FALSE, do.contour = TRUE, contour.lwd = 3, contour.col = &quot;white&quot;, contour.lty = 2, x.low.cutoff = 0.1, x.high.cutoff = 8, y.cutoff = 1, y.high.cutoff = Inf) 11.3.1.2 Differential Expression One of the most commonly performed tasks for RNA-seq data is differential gene expression (DE) analysis. Although well- established tools exist for such analysis in bulk RNA-seq data6–8, methods for scRNA-seq data are just emerging. Given the special characteristics of scRNA-seq data, including generally low library sizes, high noise levels and a large fraction of so-called ‘dropout’ events, it is unclear whether DE methods that have been devel- oped for bulk RNA-seq are suitable also for scRNA-seq ## Differential expression using DESeq2 DESeq2DETest(object, cells.1, cells.2, genes.use = NULL, assay.type = &quot;RNA&quot;, ...) ## Likelihood ratio test for zero-inflated data DiffExpTest(object, cells.1, cells.2, assay.type = &quot;RNA&quot;, genes.use = NULL, print.bar = TRUE) ## t-test DiffTTest(object, cells.1, cells.2, genes.use = NULL, print.bar = TRUE, assay.type = &quot;RNA&quot;) 11.3.2 Dimensionality Reduction 11.3.2.1 Principal Components Analysis (PCA) RunPCA() 11.3.3 Independent Components Analysis (ICA) RunICA() 11.3.3.1 Multidimensional Scaling (MDS) 11.3.4 Clustering 11.3.4.1 Kmeans DoKMeans(object, genes.use = NULL, k.genes = NULL, k.cells = 0, k.seed = 1, do.plot = FALSE, data.cut = 2.5, k.cols = PurpleAndYellow(), set.ident = TRUE, do.constrained = FALSE, assay.type = &quot;RNA&quot;, ...) 11.3.4.2 Louvain ## Neighborhood graph BuildSNN(object, genes.use = NULL, reduction.type = &quot;pca&quot;, dims.use = NULL, k.param = 10, plot.SNN = FALSE, prune.SNN = 1/15, print.output = TRUE, distance.matrix = NULL, force.recalc = FALSE, filename = NULL, save.SNN = TRUE, nn.eps = 0) FindClusters(object, genes.use = NULL, reduction.type = &quot;pca&quot;, dims.use = NULL, k.param = 30, plot.SNN = FALSE, prune.SNN = 1/15, print.output = TRUE, distance.matrix = NULL, save.SNN = FALSE, reuse.SNN = FALSE, force.recalc = FALSE, nn.eps = 0, modularity.fxn = 1, resolution = 0.8, algorithm = 1, n.start = 100, n.iter = 10, random.seed = 0, temp.file.location = NULL, edge.file.name = NULL) 11.3.4.3 Probabilistic (LDA) library(CountClust) library(singleCellRNASeqMouseDeng2014) deng.counts &lt;- exprs(Deng2014MouseESC) deng.meta_data &lt;- pData(Deng2014MouseESC) deng.gene_names &lt;- rownames(deng.counts) FitGoM(t(deng.counts),K=3,path_rda=&quot;data/MouseDeng2014.FitGoM.rda&quot;) 11.3.5 Check Clusters Use Classifier to predict cell cluster. See how it predicts using hold out data. ClassifyCells(object, classifier, training.genes = NULL, training.classes = NULL, new.data = NULL, ...) Visually check by comparing centroids of clusters in gene space and embedding space. GetCentroids(object, cells.use = NULL, get.exact = TRUE) 11.3.6 Visualizing/Embedding 11.3.6.1 tSNE 11.3.6.2 UMAP References "],
["batch-effects.html", "12 Batch Effects", " 12 Batch Effects "],
["correcting-batch-effects.html", "13 Correcting Batch Effects", " 13 Correcting Batch Effects "],
["functional-analysis.html", "14 Functional Analysis 14.1 Google Slides 14.2 Gene sets and signatures 14.3 Pathway analysis 14.4 inferCNV / honeybadger", " 14 Functional Analysis 14.1 Google Slides 14.2 Gene sets and signatures 14.2.1 Cell Cycle marrow &lt;- CellCycleScoring(object = marrow, s.genes = s.genes, g2m.genes = g2m.genes, set.ident = TRUE) # view cell cycle scores and phase assignments head(x = marrow@meta.data) # Visualize the distribution of cell cycle markers across RidgePlot(object = marrow, features.plot = c(&quot;PCNA&quot;, &quot;TOP2A&quot;, &quot;MCM6&quot;, &quot;MKI67&quot;), nCol = 2) # Running a PCA on cell cycle genes reveals, unsurprisingly, that cells # separate entirely by phase marrow &lt;- RunPCA(object = marrow, pc.genes = c(s.genes, g2m.genes), do.print = FALSE) PCAPlot(object = marrow) 14.3 Pathway analysis 14.4 inferCNV / honeybadger Github Page 14.4.1 Create the InferCNV Object Reading in the raw counts matrix and meta data, populating the infercnv object infercnv_obj = CreateInfercnvObject( raw_counts_matrix=&quot;../example/oligodendroglioma_expression_downsampled.counts.matrix&quot;, annotations_file=&quot;../example/oligodendroglioma_annotations_downsampled.txt&quot;, delim=&quot;\\t&quot;, gene_order_file=&quot;../example/gencode_downsampled.txt&quot;, ref_group_names=c(&quot;Microglia/Macrophage&quot;,&quot;Oligodendrocytes (non-malignant)&quot;)) 14.4.2 Filtering genes Removing those genes that are very lowly expressed or present in very few cells # filter out low expressed genes cutoff=1 infercnv_obj &lt;- require_above_min_mean_expr_cutoff(infercnv_obj, cutoff) # filter out bad cells min_cells_per_gene=3 infercnv_obj &lt;- require_above_min_cells_ref(infercnv_obj, min_cells_per_gene=min_cells_per_gene) ## for safe keeping infercnv_orig_filtered = infercnv_obj #plot_mean_chr_expr_lineplot(infercnv_obj) save(&#39;infercnv_obj&#39;, file = &#39;../example_output/infercnv_obj.orig_filtered&#39;) 14.4.3 Normalize each cell’s counts for sequencing depth infercnv_obj &lt;- infercnv:::normalize_counts_by_seq_depth(infercnv_obj) 14.4.4 Perform Anscombe normalization Suggested by Matan for removing noisy variation at low counts infercnv_obj &lt;- infercnv:::anscombe_transform(infercnv_obj) 14.4.5 Log transform the normalized counts: infercnv_obj &lt;- log2xplus1(infercnv_obj) 14.4.6 Apply maximum bounds to the expression data to reduce outlier effects threshold = mean(abs(get_average_bounds(infercnv_obj))) infercnv_obj &lt;- apply_max_threshold_bounds(infercnv_obj, threshold=threshold) 14.4.7 Initial view, before inferCNV operations: plot_cnv(infercnv_obj, out_dir=&#39;../example_output/&#39;, output_filename=&#39;infercnv.logtransf&#39;, x.range=&quot;auto&quot;, title = &quot;Before InferCNV (filtered &amp; log2 transformed)&quot;, color_safe_pal = FALSE, x.center = mean(infercnv_obj@expr.data)) 14.4.8 Perform smoothing across chromosomes infercnv_obj = smooth_by_chromosome(infercnv_obj, window_length=101, smooth_ends=TRUE) # re-center each cell infercnv_obj &lt;- center_cell_expr_across_chromosome(infercnv_obj, method = &quot;median&quot;) plot_cnv(infercnv_obj, out_dir=&#39;../example_output/&#39;, output_filename=&#39;infercnv.chr_smoothed&#39;, x.range=&quot;auto&quot;, title = &quot;chr smoothed and cells re-centered&quot;, color_safe_pal = FALSE) 14.4.9 Subtract the reference values from observations, now have log(fold change) values infercnv_obj &lt;- subtract_ref_expr_from_obs(infercnv_obj, inv_log=TRUE) plot_cnv(infercnv_obj, out_dir=&#39;../example_output/&#39;, output_filename=&#39;infercnv.ref_subtracted&#39;, x.range=&quot;auto&quot;, title=&quot;ref subtracted&quot;, color_safe_pal = FALSE) 14.4.10 Invert log values Converting the log(FC) values to regular fold change values, centered at 1 (no fold change) This is important because we want (1/2)x to be symmetrical to 1.5x, representing loss/gain of one chromosome region. infercnv_obj &lt;- invert_log2(infercnv_obj) plot_cnv(infercnv_obj, out_dir=&#39;../example_output/&#39;, output_filename=&#39;infercnv.inverted&#39;, color_safe_pal = FALSE, x.range=&quot;auto&quot;, x.center=1, title = &quot;inverted log FC to FC&quot;) 14.4.11 Removing noise infercnv_obj &lt;- clear_noise_via_ref_mean_sd(infercnv_obj, sd_amplifier = 1.5) plot_cnv(infercnv_obj, out_dir=&#39;../example_output/&#39;, output_filename=&#39;infercnv.denoised&#39;, x.range=&quot;auto&quot;, x.center=1, title=&quot;denoised&quot;, color_safe_pal = FALSE) 14.4.12 Remove outlier data points This generally improves on the visualization infercnv_obj = remove_outliers_norm(infercnv_obj) plot_cnv(infercnv_obj, out_dir=&#39;../example_output/&#39;, output_filename=&#39;infercnv.outliers_removed&#39;, color_safe_pal = FALSE, x.range=&quot;auto&quot;, x.center=1, title = &quot;outliers removed&quot;) 14.4.13 Find DE genes by comparing the mutant types to normal types, BASIC Runs a t-Test comparing tumor/normal for each patient and normal sample, and masks out those genes that are not significantly DE. plot_data = infercnv_obj@expr.data high_threshold = max(abs(quantile(plot_data[plot_data != 0], c(0.05, 0.95)))) low_threshold = -1 * high_threshold infercnv_obj2 &lt;- infercnv:::mask_non_DE_genes_basic(infercnv_obj, test.use = &#39;t&#39;, center_val=1) plot_cnv(infercnv_obj2, out_dir=&#39;../example_output/&#39;, output_filename=&#39;infercnv.non-DE-genes-masked&#39;, color_safe_pal = FALSE, x.range=c(low_threshold, high_threshold), x.center=1, title = &quot;non-DE-genes-masked&quot;) 14.4.14 Additional Information 14.4.14.1 Online Documentation For additional explanations on files, usage, and a tutorial please visit the wiki. 14.4.14.2 TrinityCTAT This tool is a part of the TrinityCTAT toolkit focused on leveraging the use of RNA-Seq to better understand cancer transcriptomes. To find out more please visit TrinityCTAT 14.4.14.3 Applications This methodology was used in: Anoop P. Patel et al. Single-cell RNA-seq highlights intratumoral heterogeneity in primary glioblastoma. Science. 2014 Jun 20: 1396-1401 Tirosh I et al.Dissecting the multicellular ecosystem of metastatic melanoma by single-cell RNA-seq. Science. 2016 Apr 8;352(6282):189-96 "],
["pseudotime-cell-trajectories.html", "15 Pseudotime Cell Trajectories 15.1 Google Slides 15.2 Comparison Abstract 15.3 What is Pseudotime 15.4 Inferring Pseudotime", " 15 Pseudotime Cell Trajectories Comparison: Cell Trajectories Slingshot Paper Diffusion pseudotime Diffusion maps for high-dimensional single-cell analysis 15.1 Google Slides 15.2 Comparison Abstract Using single-cell -omics data, it is now possible to computationally order cells along trajectories, allowing the unbiased study of cellular dynamic processes. Since 2014, more than 50 trajectory inference methods have been developed, each with its own set of methodological characteristics. As a result, choosing a method to infer trajectories is often challenging, since a comprehensive assessment of the performance and robustness of each method is still lacking. In order to facilitate the comparison of the results of these methods to each other and to a gold standard, we developed a global framework to benchmark trajectory inference tools. Using this framework, we compared the trajectories from a total of 29 trajectory inference methods, on a large collection of real and synthetic datasets. We evaluate methods using several metrics, including accuracy of the inferred ordering, correctness of the network topology, code quality and user friendliness. We found that some methods, including Slingshot (Street et al. 2018), TSCAN (Z. Ji and Ji 2016) and Monocle DDRTree (Trapnell et al. 2014), clearly outperform other methods, although their performance depended on the type of trajectory present in the data. Based on our benchmarking results, we therefore developed a set of guidelines for method users. However, our analysis also indicated that there is still a lot of room for improvement, especially for methods detecting complex trajectory topologies. Our evaluation pipeline can therefore be used to spearhead the development of new scalable and more accurate methods, and is available at github.com/dynverse/dynverse. (Saelens et al. 2018) 15.3 What is Pseudotime Trajectory inference methods. 15.4 Inferring Pseudotime Tree, Graph, Linear, Bifurcation, Multfurcation, Cycle 15.4.1 Diffusion Maps 15.4.2 Tree Methods 15.4.3 Model Based Methods knitr::include_graphics(&quot;images/PseudotimeComparisonGuidelines.png&quot;) References "],
["spatial-genomics.html", "16 Spatial Genomics", " 16 Spatial Genomics ? Maybe going away ? "],
["functional-pseudotime-analysis.html", "17 Functional Pseudotime Analysis", " 17 Functional Pseudotime Analysis "],
["single-cell-multiomic-technologies.html", "18 Single Cell Multiomic Technologies", " 18 Single Cell Multiomic Technologies "],
["cite-seq-and-scatac-seq.html", "19 CITE-seq and scATAC-seq", " 19 CITE-seq and scATAC-seq "],
["single-cell-resources.html", "20 Single Cell Resources 20.1 Comprehensive list of single-cell resources 20.2 Computational packages for single-cell analysis 20.3 eLife Commentary on the Human Cell Atlas 20.4 Online courses", " 20 Single Cell Resources 20.1 Comprehensive list of single-cell resources https://github.com/seandavi/awesome-single-cell 20.2 Computational packages for single-cell analysis http://bioconductor.org/packages/devel/workflows/html/simpleSingleCell.html https://satijalab.org/seurat/ https://scanpy.readthedocs.io/ 20.3 eLife Commentary on the Human Cell Atlas link - Nature Commentary on the Human Cell Atlas - https://www.nature.com/news/the-human-cell-atlas-from-vision-to-reality-1.22854 20.4 Online courses https://hemberg-lab.github.io/scRNA.seq.course/ https://github.com/SingleCellTranscriptomics "],
["references.html", "References", " References "]
]
