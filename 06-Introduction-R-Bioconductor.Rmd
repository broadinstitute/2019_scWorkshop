---
title: "06-Introduction-R"
output: html_document
---

```{r, echo=FALSE}
library(knitr)
opts_chunk$set(out.width='90%', fig.align = 'center')


library(Seurat)
library(Matrix)
library(ggplot2)
```


# Introduction R/Bioconductor

```{bash, eval = FALSE, echo = FALSE}
mkdir data
wget https://s3-us-west-2.amazonaws.com/10x.files/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz -O data/pbmc3k_filtered_gene_bc_matrices.tar.gz
cd data; tar -xzf pbmc3k_filtered_gene_bc_matrices.tar.gz
cd ..
```

## Start Environment

```{bash, eval = FALSE}
## maybe take away the --rm so they can save the container for later
## run from your home directory
cd 

## example for user17
docker run --rm -it -e PASSWORD=train \
  -v $PWD/Share:/Share \
  -v $PWD:/mydir \
  -p 9017:8787 kdgosik/scellbern2019
```

**Explaination of commands**
```{bash, eval = FALSE}
  - docker: command to run docker
  - run: asking docker to run a container
  - --rm: flag to remove the container when you exit from it
      - nothing will be saved from your session to access again later
      - this flag can be removed to keep container
  - -it: flag to run the container interactively
  - - this will keep all session output displaying on the terminal
  - - to stop container go to terminal and press Crtl+c
  - -v $PWD/Share:/Share: map the share directory from AWS to Share inside docker container
  - -v $PWD:/mydir: map your home directory to a directory inside docker container called home
  - -p 9017:8787: map docker container port of 8787(rstudio port default) to your computer port 9017
  - kdgosik/scellbern2019: the image to run.  It will be the image into a container if not already built on your computer
    - [image link](https://hub.docker.com/r/kdgosik/scellbern2019)
```

[localhost:9017](https://localhost:9017)
or on AWS
[<AWS PUBLIC IP ADDRESS>:9017](https://:9017)

ec2-<AWS PUBLIC IP ADDRESS>.us-west-2.compute.amazonaws.com:<PORT NUMBER>
ec2-54-202-32-102.us-west-2.compute.amazonaws.com:9017

  - R/Rstudio parts
  - Data Types and classes
  - Packages and where to get them
  - S3 vs S4
  - Visualizations and ggplot
  
  
  - Installing packages
  - Data-types
  - Data manipulation, slicing
  - Strings manipulations
  - Introducing object oriented programming / S4 objects
  - Visualization tools
  - Bonus create FeaturePlot from Seurat in base ggplot
  - Bonus: run RSEM on Dana’s bam files if you are bored 
  

## Installing packages

### CRAN

The Comprehensive R Archive Network [CRAN](https://cran.r-project.org/) is the biggest archive of R packages. There are few requirements for uploading packages besides building and installing succesfully, hence documentation and support is often minimal and figuring how to use these packages can be a challenge it itself. CRAN is the default repository R will search to find packages to install:

```{r, eval=FALSE}
install.packages("devtools")

# or multiple packages

install.packages(c("ggplot2", "stringr"))
```

### Github

[Github](https://github.com/) isn't specific to R, any code of any type in any state can be uploaded. There is no guarantee a package uploaded to github will even install, nevermind do what it claims to do. R packages can be downloaded and installed directly from github using the "devtools" package installed above.

```{r, eval=FALSE}
## username/repository
devtools::install_github("satijalab/seurat") # latest stable version of Seurat package
```

Github is also a version control system which stores multiple versions of any package. By default the most recent "master" version of the package is installed. If you want an older version or the development branch this can be specified using the "ref" parameter:

```{r, eval=FALSE}
# different branch
devtools::install_github("satijalab/seurat", ref="release3.0")

# previous commit
## Merge branch 'develop' into feat/MultiModal
##  - Shiwei Zheng committed on Jul 2, 2018
devtools::install_github("tallulandrews/M3Drop", ref="551014f488770627ab154a62e59d49df5df98a3f")
```
Note: make sure you re-install the M3Drop master branch for later in the course.

### Bioconductor

Bioconductor is a repository of R-packages specifically for biological analyses. It has the strictest requirements for submission, including installation on every platform and full documentation with a tutorial (called a vignette) explaining how the package should be used. Bioconductor also encourages utilization of standard data structures/classes and coding style/naming conventions, so that, in theory, packages and analyses can be combined into large pipelines or workflows. 


Bioconductor also requires creators to support their packages and has a regular 6-month release schedule. Make sure you are using the most recent release of bioconductor before trying to install packages for the course.

```{r, eval = FALSE}
## >= R 3.5.0
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
BiocManager::install("Rsamtools", version = "3.8", ask = FALSE)
```

### Source

The final way to install packages is directly from source. In this case you have to download a fully built source code file, usually packagename.tar.gz, or clone the github repository and rebuild the package yourself. Generally this will only be done if you want to edit a package yourself, or if for some reason the former methods have failed.  You can also get previous packages that aren't supported any more on the [CRAN package archive](https://cran.r-project.org/)

```{r, eval=FALSE}
## Get an old package and install from source
install.packages("GenABEL_1.8-0.tar.gz", type="source")
```

## Installation instructions:
All the packages necessary for this course are available [here](https://github.com/broadinstitute/2019_scWorkshop). A list of the packages will be on the README.md for the repository.  A script is also available inside the docker/install.R file.  





### Classes/Types


R is a high level language so the underlying data-type is generally not important. The exception if you are accessing R data directly using another language such as C, but that is beyond the scope of this course. Instead we will consider the basic data classes: numeric, integer, logical, and character, and the higher level data class called "factor". You can check what class your data is using the "class()" function.

#### Integer

```{r}
x <- 4 ## assign value of 4 to x

class(x) ## check class of x

is.integer(x) ## check if x is an integer

is.numeric(x) ## check if x is numeric

x <- as.numeric(x) ## assign y to be an numeric

is.numeric(x) ## check if the assignment worked

class(x) ## check if the assignment worked

x ## check value of x
```


#### Numeric

```{r}
## assign value of 1.414 to y

## check class of y

## check if y is numeric

## check if y is an integer

## assign y to be an integer

## check if the assignment worked

## check value of y
```


#### Logical/ Boolean

The `logical` class stores boolean truth values, i.e. TRUE and FALSE. It is used for storing the results of logical operations and conditional statements will be coerced to this class. Most other data-types can be coerced to boolean without triggering (or "throwing") error messages, which may cause unexpected behaviour.

```{r}
z <- TRUE ## assign value of TRUE to z
class(z) ## check class of z
is.logical(z) ## check if z is of logical type
```


### Data structures
  - Homogeneous
    - 1D: atomic vector
    - 2D: matrix
    - nD: array
  - Heterogeneous
    - 1D: list
    - 2D: data.frame


#### Character Vectors

```{r}
## assign a character vector with c() operator
character_vector <- c("A", "C", "T", "G", "C", "T", "G", "C", "G", "A", "T", "G", "A", "C", "G", "A", "C")

## check class
class(character_vector)


## access the 3rd element with [] operator
## *note*: R is index starts at 1 (other programming languages start at 0)
character_vector[3]


## access 3rd through 6th elemenet
character_vector[3:6]

## access the elements 1,4,7,10 with c()
character_vector[c(1, 4, 7, 10)]

## access all the A's
character_vector[grep("A", character_vector)]
```


#### Numeric Vector

The "numeric" class is the default class for storing any numeric data - integers, decimal numbers, numbers in scientific notation, etc...

```{r}
## assign a character vector with c() operator
numeric_vector <- c(1, 5, 21, 17, 98, 35, 11, 13)

## check class


## access the 5th element with [] operator


## access 2nd through 4th elemenet
```

```{r}
## backticks ` ` allow you to give names with non-typical characters
`numeric?_vecotr` <- c("A", 1, 5, 21, 17, 98, 35, 11, 13)

## check vector
`numeric?_vecotr`

## check class (Notice the quotation marks on the numbers!)
class(`numeric?_vecotr`)
```

#### Factor Vector

String/Character data is very memory inefficient to store, each letter generally requires the same amount of memory as any integer. Thus when storing a vector of strings with repeated elements it is more efficient assign each element to an integer and store the vector as integers and an additional string-to-integer association table. Thus, by default R will read in text columns of a data table as factors. 

```{r}
factor_vector <- factor(numeric_vector)
factor_vector
```


#### Named Vector

```{r}
names(numeric_vector) <- paste0("Patient", 1 : length(numeric_vector))
numeric_vector
```



#### List

```{r}
## change the c() operator to list() operator
new_list <- list("A", 1, 5, 21, 17, 98, 35, 11, 13)
new_list
```

```{r}
## get 2nd element of list
new_list[[2]]
```


```{r}
names(new_list) <- paste0("Patient", 1 : length(new_list))
new_list
```

```{r}
## get 2nd element of list
new_list[[2]]
```

  - 2D

#### matrix

**Create Matrix**
```{r}
## create numeric matrix
numeric_matrix <- matrix(sample(1:10, 100, replace = TRUE), nrow = 10, ncol = 10)
class(numeric_matrix) ## check class
```


**Check Structure**
```{r}
str(numeric_matrix)
```

**Get 3rd Row**
```{r}
## get 3rd row
numeric_matrix[3, ]
```


**Get 4th Column**
```{r}
## get 4th colum
numeric_matrix[, 4]
```



####  data.frame

**Get data.frame**
```{r}
## built in R data.frame iris
iris
```

**Check Class**
```{r}

```

**Check Structure**
```{r}

```

**Get 3rd Row**
```{r}
## get 3rd row

```


**Get 4th Column**
```{r}
## get 4th colum

```

**Get 3rd Row**
```{r}
## get 3rd row
numeric_matrix[3, ]
```


**Get Species Variable**
```{r}
## get variable
iris$Species
```



### Detour to S3/S4

  - S3 most of R uses
  - Bioconductor requires R packages to be written as S4 objects
  - OO field guide
  - Closer to a typical programming language
    - Classes/Methods and Generics
    - Lots of Generics implemented for Bioinformatics!
  
Different way to access values.  Need to use the @ symbol instead of $

```{r, eval= FALSE}
## example
object@
```


#### Sparse Matrix

Triplet format for storing a matrix
row, column, value
i, p, x


Different from base R.  Uses the S4 methods that Bioconductor uses. 
```{r}
sparse_matrix <- pbmc_small@data[1:10, ]
class(sparse_matrix)
```


**ith row - 1**
```{r}
sparse_matrix@i
```

**pth column - 1**
```{r}
sparse_matrix@p
```


**value**
```{r}
sparse_matrix@x
```

**Get First Value**
```{r}
sparse_matrix[2,1]
```
**dense matrix**
```{r}
dense_matrix <- as.matrix(sparse_matrix)
class(dense_matrix)
```

```{r}
str(dense_matrix)
```

**Get First Value**
```{r}
dense_matrix[2,1]
```



#### Functions

```{r, eval = FALSE}

create_function <- function(x) {
  
}
```



#### Reading Files

```{r, eval = FALSE}

## read csv files
read.csv("PATH/TO/FILENAME.csv")

## read tsv files
read.delim("PATH/TO/FILENAME.tsv", sep = '/t)

```


## More information

You can get more information about any R commands relevant to these datatypes using by typing `?function` in an interactive session.


    
## Grammer of Graphics (ggplot2)


### What is ggplot2?

ggplot2 is an R package designed by Hadley Wickham which facilitates data plotting. In this lab, we will touch briefly on some of the features of the package. If you would like to learn more about how to use ggplot2, we would recommend reading "ggplot2 Elegant graphics for data analysis", by Hadley Wickham or checking out his original paper on the [package](http://vita.had.co.nz/papers/layered-grammar.pdf)


  - Data: Always start with the data, identify the dimensions you want to visualize.
  - Aesthetics: Confirm the axes based on the data dimensions, positions of various data points in the plot. Also check if any form of encoding is needed including size, shape, color and so on which are useful for plotting multiple data dimensions.
  - Scale: Do we need to scale the potential values, use a specific scale to represent multiple values or a range?
  - Geometric objects: These are popularly known as ‘geoms’. This would cover the way we would depict the data points on the visualization. Should it be points, bars, lines and so on?
  - Statistics: Do we need to show some statistical measures in the visualization like measures of central tendency, spread, confidence intervals?
  - Facets: Do we need to create subplots based on specific data dimensions?
  - Coordinate system: What kind of a coordinate system should the visualization be based on — should it be cartesian or polar?


```{r, eval = FALSE, echo = FALSE}
# If you don't have Tmisc installed, first install devtools, then install
# from github: install.packages('devtools')
# devtools::install_github('stephenturner/Tmisc')
library(Tmisc)
library(ggplot2)
data(quartet)

p <- ggplot(quartet, aes(x, y)) + geom_point()
p <- p + geom_smooth(method = lm, se = FALSE)
p <- p + facet_wrap(~set)
p
```



### Principles of ggplot2

* Your data must be a dataframe if you want to plot it using ggplot2. 
* Use the `aes` mapping function to specify how variables in the dataframe map to features on your plot
* Use geoms to specify how your data should be represented on your graph eg. as a scatterplot, a barplot, a boxplot etc.


  - Data: Always start with the data, identify the dimensions you want to visualize.
```{r}
library(Seurat)
library(ggplot2)

gbm <- pbmc_small@data

gbm <- as.data.frame(as.matrix(t(gbm)))

new_plot <- ggplot(gbm)
```

  - Aesthetics: Confirm the axes based on the data dimensions, positions of various data points in the plot. Also check if any form of encoding is needed including size, shape, color and so on which are useful for plotting multiple data dimensions.

**1D Plots**
```{r}
new_plot <- ggplot(gbm, aes(x = MS4A1))
new_plot
```

  - Scale: Do we need to scale the potential values, use a specific scale to represent multiple values or a range?
  
  - Geometric objects: These are popularly known as ‘geoms’. This would cover the way we would depict the data points on the visualization. Should it be points, bars, lines and so on?
  
```{r}
## ggplot(gbm, aes(x = MS4A1)) + geom_histogram()
new_plot2 <- new_plot + geom_histogram()
```

#### Lab A

Use different geom_ to make a different plots
  - try _bar()
  - try _density()
  
```{r}
new_plot
```



  - Statistics: Do we need to show some statistical measures in the visualization like measures of central tendency, spread, confidence intervals?
  
  
```{r}
ggplot(gbm, aes(x = MS4A1)) + geom_histogram() + stat_bin(bins = 10)
```



**2D Plots**
  
```{r}
ggplot(gbm, aes(MS4A1, CD79B)) + geom_point()
```

```{r}
ggplot(gbm, aes(MS4A1, CD79B)) + geom_point() + stat_smooth(method = "lm")
```


```{r}
ggplot(gbm, aes(MS4A1, CD79B)) + geom_point() + stat_smooth(method = "lm") + geom_text(aes(label = rownames(gbm)))
```

  - Facets: Do we need to create subplots based on specific data dimensions?
  - Coordinate system: What kind of a coordinate system should the visualization be based on — should it be cartesian or polar?




<!-- Hember Lab Example


### Using the `aes` mapping function

The `aes` function specifies how variables in your dataframe map to features on your plot. To understand how this works, let's look at an example:

```{R, eval=FALSE, message=FALSE}
library(ggplot2)
set.seed(1)
counts <- as.data.frame(matrix(rpois(100, lambda = 10), ncol=10, nrow=10))
Gene_ids <- paste("gene", 1:10, sep = "")
colnames(counts) <- paste("cell", 1:10, sep = "")
counts <- data.frame(Gene_ids, counts)
counts
ggplot(data = counts, mapping = aes(x = cell1, y = cell2))
```

Let's take a closer look at the final command, `ggplot(data = counts, mapping = aes(x = cell1, y = cell2))`. `ggplot()` initialises a ggplot object and takes the arguments `data` and `mapping`. We pass our dataframe of counts to `data` and use the `aes()` function to specify that we would like to use the variable cell1 as our x variable and the variable cell2 as our y variable.

Task 1: Modify the command above to initialise a ggplot object where cell10 is the x variable and cell8 is the y variable.

Clearly, the plots we have just created are not very informative because no data is displayed on them. To display data, we will need to use geoms.

### Geoms

We can use geoms to specify how we would like data to be displayed on our graphs. For example, our choice of geom could specify that we would like our data to be displayed as a scatterplot, a barplot or a boxplot.

Let's see how our graph would look as a scatterplot.

```{R, eval=FALSE}
ggplot(data = counts, mapping = aes(x = cell1, y = cell2)) + geom_point()
```

Now we can see that there doesn't seem to be any correlation between gene expression in cell1 and cell2. Given we generated `counts` randomly, this isn't too surprising.

Task 2: Modify the command above to create a line plot. Hint: execute `?ggplot` and scroll down the help page. At the bottom is a link to the ggplot package index. Scroll through the index until you find the geom options.

### Plotting data from more than 2 cells

So far we've been considering the gene counts from 2 of the cells in our dataframe. But there are actually 10 cells in our dataframe and it would be nice to compare all of them. What if we wanted to plot data from all 10 cells at the same time?

At the moment we can't do this because we are treating each individual cell as a variable and assigning that variable to either the x or the y axis. We could create a 10 dimensional graph to plot data from all 10 cells on, but this is a) not possible to do with ggplot and b) not very easy to interpret. What we could do instead is to tidy our data so that we had one variable representing cell ID and another variable representing gene counts, and plot those against each other. In code, this would look like:

```{R, eval=FALSE}
counts<-gather(counts, colnames(counts)[2:11], key = 'Cell_ID', value='Counts')
head(counts)
```

Essentially, the problem before was that our data was not tidy because one variable (Cell_ID) was spread over multiple columns. Now that we've fixed this problem, it is much easier for us to plot data from all 10 cells on one graph.

```{R, eval=FALSE}
ggplot(counts,aes(x=Cell_ID, y=Counts)) + geom_boxplot()
```

Task 3: Use the updated `counts` dataframe to plot a barplot with Cell_ID as the x variable and Counts as the y variable. Hint: you may find it helpful to read `?geom_bar`.

Task 4: Use the updated `counts` dataframe to plot a scatterplot with Gene_ids as the x variable and Counts as the y variable.

### Plotting heatmaps

A common method for visualising gene expression data is with a heatmap. Here we will use the R package `pheatmap` to perform this analysis with some gene expression data we will name `test`.

```{R, eval=FALSE, message=FALSE}
library(pheatmap)
set.seed(2)
test = matrix(rnorm(200), 20, 10)
test[1:10, seq(1, 10, 2)] = test[1:10, seq(1, 10, 2)] + 3
test[11:20, seq(2, 10, 2)] = test[11:20, seq(2, 10, 2)] + 2
test[15:20, seq(2, 10, 2)] = test[15:20, seq(2, 10, 2)] + 4
colnames(test) = paste("Cell", 1:10, sep = "")
rownames(test) = paste("Gene", 1:20, sep = "")
pheatmap(test)
```

Let's take a moment to work out what this graphic is showing us. Each row represents a gene and each column represents a cell. How highly expressed each gene is in each cell is represented by the colour of the corresponding box. For example, we can tell from this plot that gene18 is highly expressed in cell10 but lowly expressed in cell1.

This plot also gives us information on the results of a clustering algorithm. In general, clustering algorithms aim to split datapoints (eg.cells) into groups whose members are more alike one another than they are alike the rest of the datapoints. The trees drawn on the top and left hand sides of the graph are the results of clustering algorithms and enable us to see, for example, that cells 4,8,2,6 and 10 are more alike one another than they are alike cells 7,3,5,1 and 9. The tree on the left hand side of the graph represents the results of a clustering algorithm applied to the genes in our dataset.

If we look closely at the trees, we can see that eventually they have the same number of branches as there are cells and genes. In other words, the total number of cell clusters is the same as the total number of cells, and the total number of gene clusters is the same as the total number of genes. Clearly, this is not very informative, and will become impractical when we are looking at more than 10 cells and 20 genes. Fortunately, we can set the number of clusters we see on the plot. Let's try setting the number of gene clusters to 2:

```{R, eval=FALSE}
pheatmap(test, kmeans_k = 2)
```

Now we can see that the genes fall into two clusters - a cluster of 8 genes which are upregulated in cells 2, 10, 6, 4 and 8 relative to the other cells and a cluster of 12 genes which are downregulated in cells 2, 10, 6, 4 and 8 relative to the other cells.

Task 5: Try setting the number of clusters to 3. Which number of clusters do you think is more informative?

### Principal Component Analysis

Principal component analysis (PCA) is a statistical procedure that uses a transformation to convert a set of observations into a set of values of linearly uncorrelated variables called principal components. The transformation is carried out so that the first principle component accounts for as much of the variability in the data as possible, and each following principle component accounts for the greatest amount of variance possible under the contraint that it must be orthogonal to the previous components.

PCA plots are a good way to get an overview of your data, and can sometimes help identify confounders which explain a high amount of the variability in your data. We will investigate how we can use PCA plots in single-cell RNA-seq analysis in more depth in a future lab, here the aim is to give you an overview of what PCA plots are and how they are generated.

Let's make a PCA plot for our `test` data. We can use the  `ggfortify` package to let ggplot know how to interpret principle components.

```{R,eval=FALSE, message=FALSE}
library(ggfortify)
Principal_Components<-prcomp(test)
autoplot(Principal_Components, label=TRUE)
```

Task 6: Compare your clusters to the pheatmap clusters. Are they related? (Hint: have a look at the gene tree for the first pheatmap we plotted)

Task 7: Produce a heatmap and PCA plot for `counts` (below):

```{R,eval=FALSE}
set.seed(1)
counts <- as.data.frame(matrix(rpois(100, lambda = 10), ncol=10, nrow=10))
rownames(counts) <- paste("gene", 1:10, sep = "")
colnames(counts) <- paste("cell", 1:10, sep = "")
```

-->



## Reference

  - [R for Data Science](https://r4ds.had.co.nz/)
  - [Advanced R](http://adv-r.had.co.nz/)
  - [Bioconductor Workflows](http://bioconductor.org/packages/release/BiocViews.html#___Workflow)
  - [Bioconductor Presentation](http://www.bioconductor.org/help/course-materials/2010/AdvancedR/S4InBioconductor.pdf)
  - [Original ggplot2 paper](http://vita.had.co.nz/papers/layered-grammar.pdf)
  - [ggplot2 reference](https://ggplot2.tidyverse.org/reference/index.html)
  - [ggplot2 cheatsheet](https://github.com/rstudio/cheatsheets/blob/master/data-visualization-2.1.pdf)
  - [blog post](https://towardsdatascience.com/a-comprehensive-guide-to-the-grammar-of-graphics-for-effective-visualization-of-multi-dimensional-1f92b4ed4149)
  
